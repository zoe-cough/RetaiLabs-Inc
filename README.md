In this Kaggle competition, we will use time-series forecasting to forecast store sales on data from Corporación Favorita, a large Ecuadorian-based grocery retailer. Specifically, we’ll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores based on Kaggle-provided data. Forecasts aren’t just for meteorologists. Governments forecast economic growth. Scientists attempt to predict the future population. And businesses forecast product demand—a common task of professional data scientists. Forecasts are especially relevant to brick-and-mortar grocery stores, which must dance delicately with how much inventory to buy. Predict a little over, and grocers are stuck with overstocked, perishable goods. Guess a little under, and popular items quickly sell out, leading to lost revenue and upset customers. More accurate forecasting, thanks to machine learning, could help ensure retailers please customers by having just enough of the right products at the right time. Current subjective forecasting methods for retail have little data to back them up and are unlikely to be automated. The problem becomes even more complex as retailers add new locations with unique needs, new products, ever-transitioning seasonal tastes, and unpredictable product marketing. For grocery stores, more accurate forecasting can decrease food waste related to overstocking and improve customer satisfaction. The results of this project, over time, might even ensure many local stores have exactly what buyers need the next time they shop. In this competition, we will predict sales for the thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Based on the objective and data given, we have determined that applying the stochastic gradient descent algorithm would be the most efficient. Qualitatively the results will be evaluated through graphs generated through the stochastic gradient descent algorithm applied, such as those generated in Homework 2 of this course. Quantitatively, we will be using Root Mean Squared Logarithmic Error to evaluate our results.
